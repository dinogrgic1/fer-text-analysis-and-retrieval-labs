{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77230ee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed8a00df369ce38f9743ed412973d72b",
     "grade": false,
     "grade_id": "cell-cbdf7d65ea58446b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "University of Zagreb\\\n",
    "Faculty of Electrical Engineering and Computing\n",
    "\n",
    "## Text Analysis and Retrieval 2021/2022\n",
    "https://www.fer.unizg.hr/predmet/apt/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee22e58",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0129f6baa6ea4e128ede5f41d446ec67",
     "grade": false,
     "grade_id": "cell-5e9c1e104dec0dd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "------------------------------\n",
    "\n",
    "### Basics of NLP\n",
    "\n",
    "*Version: 1.1*\n",
    "\n",
    "(c) 2022 Josip Jukić, Jan Šnajder\n",
    "\n",
    "Submission deadline: **April 6, 2022, 23:59 CET** \n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6333437b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7dec4757a699e04f5ca4b7db9a25f481",
     "grade": false,
     "grade_id": "cell-b25d76fa7c847af2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "Hello visitor, this lab assignment consists of three parts. Your task boils down to filling out the missing parts of code and evaluating the cells. These parts are indicated by the \"YOUR CODE HERE\" template.\n",
    "\n",
    "Each subtask is supplemented by several tests that you can run. Apart from that, there are additional test that will be executed after submition. If your solution is valid and it passes all of the visible tests, there shouldn't be any problems with the additional tests.\n",
    "\n",
    "**IMPORTANT: Don't change the names of the predefined methods or random seeds**, because the tests won't be executed properly.\n",
    "\n",
    "You're required to do this assignment **on your own**.\n",
    "\n",
    "If you stumble upon problems, please refer to josip.jukic@fer.hr for office hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336f31b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd1654b2c7c8de8e1d1cfaeeee261ec2",
     "grade": false,
     "grade_id": "cell-150c23ae802b9522",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52503faa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0398d566c69a62089f0eb60546d6340d",
     "grade": false,
     "grade_id": "cell-95afad8333fec3bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "third-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d3b8c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b155864b06eca3cc7daa9d3c05433e43",
     "grade": false,
     "grade_id": "cell-6eb6dc1bc414cf1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will use [spaCy](https://spacy.io/) exetensively in this assigment. You are advised to study the main aspects of this tool. You can go through the basics [here](https://spacy.io/usage/spacy-101). We recommend that you go through the procedures that we covered in the lectures: tokenization, lemmatization, part-of-speech (POS) tagging, and named entity recognition (NER).\n",
    "\n",
    "Furthermore, we will rely on [NumPy](https://numpy.org/) and [pandas](https://pandas.pydata.org/) libraries. If you are not familiar with those libraries, we advise you to go through [this tutorial](https://www.hackerearth.com/practice/machine-learning/data-manipulation-visualisation-r-python/tutorial-data-manipulation-numpy-pandas-python/tutorial/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "49891d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d800562",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18574758fbae85b229fb5ad20ca9cdda",
     "grade": false,
     "grade_id": "cell-16202be1385f6781",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (a)\n",
    "Process the example below with spaCy. Tokenize the document and gather the tokens in a list. Finally, print the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e7d34e4b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76f9573e9524d0566357ec211312ce57",
     "grade": false,
     "grade_id": "cell-8fa80d1ece04d737",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ex1_a1 = (\n",
    "    \"A wizard is never late, Frodo Baggins. \"\n",
    "    \"Nor is he early; he arrives precisely when he means to.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d8bfdd25",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eece1ba6d97bcb94ee0a4e5ae7499ac0",
     "grade": false,
     "grade_id": "cell-10252e22a675688e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "wizard\n",
      "is\n",
      "never\n",
      "late\n",
      ",\n",
      "Frodo\n",
      "Baggins\n",
      ".\n",
      "Nor\n",
      "is\n",
      "he\n",
      "early\n",
      ";\n",
      "he\n",
      "arrives\n",
      "precisely\n",
      "when\n",
      "he\n",
      "means\n",
      "to\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "tokens_a1 = nlp.tokenizer(ex1_a1)\n",
    "for token in tokens_a1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a8590",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbc65ec903d48d3665d4227c2343f2bc",
     "grade": false,
     "grade_id": "cell-bb0718d5e7f50e40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (b)\n",
    "Implement `sentencizer` using [spaCy](https://spacy.io/usage/linguistic-features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f8da2f50",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "640f18a880a339d3a99335a3a8164771",
     "grade": false,
     "grade_id": "cell-f24e1081f2af60b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sentencizer(text):\n",
    "    doc = nlp(text)\n",
    "    return [str(x) for x in list(doc.sents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d39e0309",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7998a7e3d2e527b89800c50bdca72ba7",
     "grade": true,
     "grade_id": "cell-cda5936073984160",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sentencizer(\"Sentence no. 1. Sentence no. 2.\") == [\n",
    "    \"Sentence no. 1.\",\n",
    "    \"Sentence no. 2.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab61006",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dada93ac32be275cfea235c17f9ba0f4",
     "grade": false,
     "grade_id": "cell-a39ece84bbd22997",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (c)\n",
    "\n",
    "Implement `lemmatizer` using [spaCy](https://spacy.io/usage/linguistic-features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "462c67dd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e0bc45a957906ca13e967ab5e083fbc",
     "grade": false,
     "grade_id": "cell-759698a86a73114f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "60cad45e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28b18c2fc2b5c5c6020c81abcd5f7f26",
     "grade": true,
     "grade_id": "cell-1381a0323dde41cc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert lemmatizer(ex1_a1) == [\n",
    "    \"a\",\n",
    "    \"wizard\",\n",
    "    \"be\",\n",
    "    \"never\",\n",
    "    \"late\",\n",
    "    \",\",\n",
    "    \"Frodo\",\n",
    "    \"Baggins\",\n",
    "    \".\",\n",
    "    \"nor\",\n",
    "    \"be\",\n",
    "    \"he\",\n",
    "    \"early\",\n",
    "    \";\",\n",
    "    \"he\",\n",
    "    \"arrive\",\n",
    "    \"precisely\",\n",
    "    \"when\",\n",
    "    \"he\",\n",
    "    \"mean\",\n",
    "    \"to\",\n",
    "    \".\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ccb113",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "300d915802e7c3337f5d6fcd3ede3ed3",
     "grade": false,
     "grade_id": "cell-a20b39684be6b375",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (d)\n",
    "\n",
    "Implement the `ngrams` methods. You might find the [`tee`](https://www.geeksforgeeks.org/python-itertools-tee/) method from the `itertools` package useful, but you're not obliged to use it. The method should return a generator. Plase refer to the [link](https://wiki.python.org/moin/Generators) if you aren't familiar with Python generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "06186b52",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cc9b2358491234483fce15870678054",
     "grade": false,
     "grade_id": "cell-66b11d5510c3d6ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from itertools import tee\n",
    "\n",
    "\n",
    "def ngrams(sequence, n, **kwargs):\n",
    "    result = []\n",
    "    curr_n = n - 1\n",
    "    for itter in tee(sequence, len(sequence) - n + 1):\n",
    "        result.append(tuple(list(itter)[curr_n - n + 1: curr_n + 1]))\n",
    "        curr_n = curr_n + 1\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a72da564",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0b5586930150617ae69345587517487",
     "grade": true,
     "grade_id": "cell-01b516b6b34b5d58",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert list(ngrams(lemmatizer(ex1_a1), 2)) == [\n",
    "    (\"a\", \"wizard\"),\n",
    "    (\"wizard\", \"be\"),\n",
    "    (\"be\", \"never\"),\n",
    "    (\"never\", \"late\"),\n",
    "    (\"late\", \",\"),\n",
    "    (\",\", \"Frodo\"),\n",
    "    (\"Frodo\", \"Baggins\"),\n",
    "    (\"Baggins\", \".\"),\n",
    "    (\".\", \"nor\"),\n",
    "    (\"nor\", \"be\"),\n",
    "    (\"be\", \"he\"),\n",
    "    (\"he\", \"early\"),\n",
    "    (\"early\", \";\"),\n",
    "    (\";\", \"he\"),\n",
    "    (\"he\", \"arrive\"),\n",
    "    (\"arrive\", \"precisely\"),\n",
    "    (\"precisely\", \"when\"),\n",
    "    (\"when\", \"he\"),\n",
    "    (\"he\", \"mean\"),\n",
    "    (\"mean\", \"to\"),\n",
    "    (\"to\", \".\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea0feaf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "805632bc6f160ec920cb46d8ac316635",
     "grade": false,
     "grade_id": "cell-adf3d7b2e18c3c03",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2. News classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70ebb3c",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "Load the prepared BBC news data to a `pandas` dataframe named `df_bbc`. Explore the dataset structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "93bc621a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db8a261fbf823db01013aaade4756761",
     "grade": false,
     "grade_id": "cell-46a1f24f0267c57e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  news           type\n",
      "0    New 'yob' targets to be unveiled\\n \\n Fifty ne...       politics\n",
      "1    Newcastle line up Babayaro\\n \\n Newcastle mana...          sport\n",
      "2    Europe backs digital TV lifestyle\\n \\n How peo...           tech\n",
      "3    Fears raised over ballet future\\n \\n Fewer chi...  entertainment\n",
      "4    Barkley fit for match in Ireland\\n \\n England ...          sport\n",
      "..                                                 ...            ...\n",
      "195  Wales 'must learn health lessons'\\n \\n The new...       politics\n",
      "196  Clarke to press on with ID cards\\n \\n New Home...       politics\n",
      "197  Artists' secret postcards on sale\\n \\n Postcar...  entertainment\n",
      "198  Lopez misses UK charity premiere\\n \\n Jennifer...  entertainment\n",
      "199  February poll claim 'speculation'\\n \\n Reports...       politics\n",
      "\n",
      "[200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_bbc = pd.read_csv(\"bbc.csv\")\n",
    "print(df_bbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180a03e9",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "To make the classification task a bit more challenging, we want to remove the news title from the text.\\\n",
    "Additionally, we will replace all whitespaces with single spaces. Implement title removal and whitespace replacement in `clean_text`.\\\n",
    "E.g., \"This \\n is  \\t an &nbsp;&nbsp;&nbsp;&nbsp; example. \" -> \"This is an example.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3a13f8b4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64739bab014639562d3c2be4139a6ada",
     "grade": false,
     "grade_id": "cell-51a7b044e7fb5900",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Removes news title and replaces all whitespaces with single spaces.\n",
    "    Returns preprocessed text.\n",
    "    \"\"\"\n",
    "    text = ''.join(text.split('\\n')[1:])\n",
    "    return ' '.join(text.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7d7cc6d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f669133bd4f9965634a4003e0fa4fbe2",
     "grade": true,
     "grade_id": "cell-fce2e38e985bdf90",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (\n",
    "    clean_text(\"Breaking news\\nClever Hans \\t learns  to integrate.\")\n",
    "    == \"Clever Hans learns to integrate.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "04359889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbc[\"text\"] = df_bbc.news.apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dde023",
   "metadata": {},
   "source": [
    "#### (c)\n",
    "(1) Implement an abstract pipeline in `preprocess_pipe`. The method receieves a sequence of texts and a pipe function, which is used to preprocess documents in combination with the spaCy model `nlp` that we loaded at the beggining. We recommend you to use [`pipe`](https://spacy.io/usage/processing-pipelines).\\\n",
    "(2) Implement `lemmatize_pipe` that collects lemmas and returns a list of n-grams ranging from `ngram_min` to `ngram_max`. Additonally, **truncate** the documents to `max_len` tokens and **remove the stop words**. Refer to the tests below to see how this method should behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3a8d5c10",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "871d62e1e2fecb7c68afcc50a4a1c15d",
     "grade": false,
     "grade_id": "cell-d767fae648cfcd8c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_pipe(doc, max_len, ngram_min, ngram_max):\n",
    "    \"\"\"\n",
    "    Removes stopword, truncates the document to `max_len` tokens,\n",
    "    and returns lemma n-grams in range [`ngram_min`, `ngram_max`].\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "def preprocess_pipe(texts, pipe_fn):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8fa0dc4a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eaaf424e75df3ace41f83b75cca082e4",
     "grade": true,
     "grade_id": "cell-17c77fd435574993",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9120/2779690122.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m ]\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mpreprocess_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex2_c1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipe_fn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msol2_c1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m ex2_c2 = [\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9120/728398080.py\u001b[0m in \u001b[0;36mpreprocess_pipe\u001b[1;34m(texts, pipe_fn)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipe_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "pipe_fn = partial(lemmatize_pipe, max_len=100, ngram_min=1, ngram_max=2)\n",
    "\n",
    "ex2_c1 = [\"Text no. 1\", \"Text no. 2\"]\n",
    "sol2_c1 = [\n",
    "    [(\"text\",), (\".\",), (\"1\",), (\"text\", \".\"), (\".\", \"1\")],\n",
    "    [(\"text\",), (\".\",), (\"2\",), (\"text\", \".\"), (\".\", \"2\")],\n",
    "]\n",
    "\n",
    "assert preprocess_pipe(ex2_c1, pipe_fn) == sol2_c1\n",
    "\n",
    "ex2_c2 = [\n",
    "    \"It’s a dangerous business, Frodo, going out your door.\",\n",
    "    \"You step onto the road, and if you don’t keep your feet, there’s no knowing where you might be swept off to.\",\n",
    "]\n",
    "sol2_c2 = [\n",
    "    [\n",
    "        (\"dangerous\",),\n",
    "        (\"business\",),\n",
    "        (\",\",),\n",
    "        (\"Frodo\",),\n",
    "        (\",\",),\n",
    "        (\"go\",),\n",
    "        (\"door\",),\n",
    "        (\".\",),\n",
    "        (\"dangerous\", \"business\"),\n",
    "        (\"business\", \",\"),\n",
    "        (\",\", \"Frodo\"),\n",
    "        (\"Frodo\", \",\"),\n",
    "        (\",\", \"go\"),\n",
    "        (\"go\", \"door\"),\n",
    "        (\"door\", \".\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"step\",),\n",
    "        (\"road\",),\n",
    "        (\",\",),\n",
    "        (\"foot\",),\n",
    "        (\",\",),\n",
    "        (\"know\",),\n",
    "        (\"sweep\",),\n",
    "        (\".\",),\n",
    "        (\"step\", \"road\"),\n",
    "        (\"road\", \",\"),\n",
    "        (\",\", \"foot\"),\n",
    "        (\"foot\", \",\"),\n",
    "        (\",\", \"know\"),\n",
    "        (\"know\", \"sweep\"),\n",
    "        (\"sweep\", \".\"),\n",
    "    ],\n",
    "]\n",
    "\n",
    "assert preprocess_pipe(ex2_c2, pipe_fn) == sol2_c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e927475",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95eaa9fbfa6690d857b87f093ce96ab9",
     "grade": false,
     "grade_id": "cell-4f1b437a60d59263",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "pipe_fn = partial(lemmatize_pipe, max_len=100, ngram_min=1, ngram_max=2)\n",
    "\n",
    "df_bbc[\"lemmas\"] = preprocess_pipe(df_bbc.text, pipe_fn)\n",
    "df_bbc_train, df_bbc_test = train_test_split(\n",
    "    df_bbc[[\"lemmas\", \"type\"]], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41262657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Load vectorizers\n",
    "count_vectorizer = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False, min_df=3)\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False, min_df=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16506e26",
   "metadata": {},
   "source": [
    "#### (d)\n",
    "Implement `train_lr`. Run `test_performance` with count and TF-IDF vectorizer. Compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d032e1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba851ee17994c47b71e16eb24c255e91",
     "grade": false,
     "grade_id": "cell-3ffaa74fc8341360",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "\n",
    "def train_lr(df_train, vectorizer, lr_kwargs={\"max_iter\": 1000, \"solver\": \"lbfgs\"}):\n",
    "    \"\"\"\n",
    "    Receives the train set `df_train` as pd.DataFrame and extracts lemma n-grams\n",
    "    with their correspoding labels (news type).\n",
    "    The text is vectorized and used to train a logistic regression with\n",
    "    training arguments passed as `lr_kwargs`.\n",
    "    Returns the fitted model.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa13b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def test_performance(model, df_test, vectorizer):\n",
    "    X_test, y_test = df_test.lemmas, df_test.type\n",
    "    X_vec = vectorizer.transform(X_test)\n",
    "    y_pred = model.predict(X_vec)\n",
    "    print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "    return f1_score(y_pred=y_pred, y_true=y_test, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fffebe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85d7002a20bc26808eb96c9c519748cb",
     "grade": true,
     "grade_id": "cell-b4268c290c91d4c9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a933bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count vectorizer scenario\n",
    "lr = train_lr(df_bbc_train, count_vectorizer)\n",
    "f1 = test_performance(lr, df_bbc_test, count_vectorizer)\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef13b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF-IDF vectorizer scenario\n",
    "lr = train_lr(df_bbc_train, tfidf_vectorizer)\n",
    "f1 = test_performance(lr, df_bbc_test, tfidf_vectorizer)\n",
    "print(f\"f1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64facf03",
   "metadata": {},
   "source": [
    "### 3. Named entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ff418",
   "metadata": {},
   "source": [
    "Named entity recognition (NER) is a NLP that seeks to classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, quantities, monetary values, percentages, etc. Refer to [Jurafsky \\& Martin, Speech and Language Processing, Chapter 17](https://web.stanford.edu/~jurafsky/slp3/17.pdf) for additional information.\n",
    "\n",
    "In this task, we will try out two approaches:\n",
    "1. **classification**, where we classify named entities for each word in a document,\n",
    "2. and **sequence labeling**, a more natural way to solve NER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d891e",
   "metadata": {},
   "source": [
    "First, let's see spaCy's visualization tool `displacy` in action. We will take the first document from our data frame and render named entities with spaCy's default NER model. Although there are some minor innacuracies, spaCy's NER model generally performs very well (~90% accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ebf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "\n",
    "doc = nlp(df_bbc.news.iloc[0])\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07d6da4",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "We want to use spaCy's deafult model to produce silver standard NER labels for our BBC news dataset. First step is to implement `entity_pipe`, a method that extracts POS tags and NER labels, which we will pass as an argument to `preprocess_pipe`. `entity_pipe` receives a spaCy document, extracts triplets in the form of (token, POS tag, named entity label), and returns the list of collected triplets. Refer to [spaCy's documention for NER](https://spacy.io/usage/linguistic-features#named-entities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf8c6bd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "467a7938cfe111e1fc1a8e1c1f2d5f2b",
     "grade": false,
     "grade_id": "cell-fd433993b28d314c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def entity_pipe(doc):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b328ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11ede27ac8ab161d7a4d486237198c50",
     "grade": true,
     "grade_id": "cell-d6d93f8d56b0d8e9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "ex3_a1 = [\n",
    "    \"One does not simply walk into Mordor.\",\n",
    "    \"What about second breakfast?\",\n",
    "]\n",
    "sol3_a1 = [\n",
    "    [\n",
    "        (\"One\", \"PRP\", \"O\"),\n",
    "        (\"does\", \"VBZ\", \"O\"),\n",
    "        (\"not\", \"RB\", \"O\"),\n",
    "        (\"simply\", \"RB\", \"O\"),\n",
    "        (\"walk\", \"VB\", \"O\"),\n",
    "        (\"into\", \"IN\", \"O\"),\n",
    "        (\"Mordor\", \"NNP\", \"B-ORG\"),\n",
    "        (\".\", \".\", \"O\"),\n",
    "    ],\n",
    "    [\n",
    "        (\"What\", \"WP\", \"O\"),\n",
    "        (\"about\", \"IN\", \"O\"),\n",
    "        (\"second\", \"JJ\", \"B-ORDINAL\"),\n",
    "        (\"breakfast\", \"NN\", \"O\"),\n",
    "        (\"?\", \".\", \"O\"),\n",
    "    ],\n",
    "]\n",
    "assert preprocess_pipe(ex3_a1, entity_pipe) == sol3_a1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c69b04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "30e959aa7eca996b98a9b41d3b7c8ed8",
     "grade": false,
     "grade_id": "cell-3a37ef269efc526a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will only the first 50 documents to reduce the computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73af685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbc_trunc = df_bbc[:50].copy()\n",
    "\n",
    "df_bbc_trunc[\"tags\"] = preprocess_pipe(df_bbc_trunc[\"text\"], entity_pipe)\n",
    "data = sum(df_bbc_trunc[\"tags\"], [])\n",
    "tokens, pos, tags = zip(*data)\n",
    "df_iob = pd.DataFrame({\"token\": tokens, \"POS\": pos, \"tag\": tags})\n",
    "df_iob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745e0688",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bde96fc0c7fde0b4f522a516ffe4f6f",
     "grade": false,
     "grade_id": "cell-19cd1a79d82d17df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (b)\n",
    "Vectorize the data in `df_iob` with [`DictVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html). You can transform the datafframe to a dictionary with [`to_dict`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html). The structure of the dictionary should look like so: [{column -> value}, … , {column -> value}]. Refer to the linked documentation to see how to utilize the `orient` argument.\n",
    "After vectorization, split the data using [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), with `test_size=0.5` and `shuffle=False` to preserve the sentence structure. We are trying to classify named entites, so you can simply use the `tag` column from `df_iob` to extract labels. You can keep them in the string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-steal",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc6458a88505e29243276ccec489156a",
     "grade": false,
     "grade_id": "cell-771cc8409e2ed46c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = None, None, None, None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4cbc36",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d24ae3f1d8bd30fa44c91e3d8ab1e1d4",
     "grade": true,
     "grade_id": "cell-08e13487d4b2350c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e4cd71a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5c03e28fc594e7eb252c21f09359f647",
     "grade": false,
     "grade_id": "cell-c98f6159909f5178",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can train your classifier now. For this purpose, let's choose Multinomial Naïve Bayes (MNB). Since MNB can learn incrementally, notice that we train our model with [`partial_fit`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.partial_fit) to reduce the computational complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "classes = np.unique(df_iob.tag.values).tolist()\n",
    "nb = MultinomialNB()\n",
    "nb.partial_fit(X_train, y_train, classes)\n",
    "\n",
    "print(classification_report(y_pred=nb.predict(X_test), y_true=y_test, labels=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6d70f2",
   "metadata": {},
   "source": [
    "For non-sparse classes, the $F_1$ score should be close to $1$. The possible explanation is that spaCy's default NER model is rule-based, which makes it easy to learn. Remeber that we used spaCy to produce silver labels. To check how the classifier performs on human-annotated data, let's explore the next dataset \"ner.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8946f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner = pd.read_csv(\"ner.csv\", encoding=\"ISO-8859-1\")\n",
    "# Fill NaNs with preceding values (for the \"Sentence #\" column).\n",
    "df_ner.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dfde73",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "93f9dd003fc8a5d3a8d9026eae8bc509",
     "grade": false,
     "grade_id": "cell-48b614c32d72b784",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Repeat the same procedure as in **(b)** with [`DictVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) on `df_clf`. Use [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), with `test_size=0.5` and `shuffle=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e69c4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "429e2dde8d5aa0c8ea218e365a7328f5",
     "grade": false,
     "grade_id": "cell-d4fbdfec3e6fea05",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df_clf = df_ner[[\"Word\", \"POS\", \"Tag\"]]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = None, None, None, None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8d11f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba7146f0e740162ab6e6b5b57716c882",
     "grade": true,
     "grade_id": "cell-8a44880e7fc3e9e7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de52b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f020728d",
   "metadata": {},
   "source": [
    "Let's drop the `O` tag, since it is the most frequent tag and it is hard to interpret the performance quality when it is included. This will give us a more realistic `F_1` score. If you wish, you can compare the results by setting `labels=classes` instead of `labels=new_classes`. If your classifier performs terribly, that is expected, so don't worry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec86735",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classes = classes.copy()\n",
    "new_classes.pop()\n",
    "print(\n",
    "    classification_report(y_pred=nb.predict(X_test), y_true=y_test, labels=new_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c05cc",
   "metadata": {},
   "source": [
    "Let's try to improve the performance with the sequence labeling approach. Specifically, we're going to use CRF. First, we have to prepare the sentence-level dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e6739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "\n",
    "sentences = df_ner.groupby(\"Sentence #\").Word.agg(lambda s: \" \".join(s)).values.tolist()\n",
    "processed = preprocess_pipe(sentences, entity_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5452f6a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59dbded5cc9fd965a775314629ff6986",
     "grade": false,
     "grade_id": "cell-b81b065411cd357a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (c)\n",
    "Implement missing features in `token2features`:\n",
    "- -1:token.lower() = preceding token in lowercase\n",
    "- -1:token.istitle() = is the preceding token a title\n",
    "- -1:token.isupper() = is the preceding token a digit\n",
    "- -1:postag = POS tag of the preceding token\n",
    "\n",
    "Analogously, add the same features for succeeding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197cedf6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1f924372b07f791f8a0ff32da3dc8aa",
     "grade": false,
     "grade_id": "cell-4f8ca4c7a8c34404",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def token2features(sent, i):\n",
    "    token = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        \"bias\": 1.0,\n",
    "        \"token.lower()\": token.lower(),\n",
    "        \"token[-3:]\": token[-3:],\n",
    "        \"token[-2:]\": token[-2:],\n",
    "        \"token.isupper()\": token.isupper(),\n",
    "        \"token.istitle()\": token.istitle(),\n",
    "        \"token.isdigit()\": token.isdigit(),\n",
    "        \"postag\": postag,\n",
    "        \"postag[:2]\": postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        features.update(\n",
    "            {\n",
    "                \"-1:token.lower()\": None,\n",
    "                \"-1:token.istitle()\": None,\n",
    "                \"-1:token.isupper()\": None,\n",
    "                \"-1:postag\": None,\n",
    "            }\n",
    "        )\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    else:\n",
    "        features[\"BOS\"] = True\n",
    "    if i < len(sent) - 1:\n",
    "        features.update(\n",
    "            {\n",
    "                \"+1:token.lower()\": None,\n",
    "                \"+1:token.istitle()\": None,\n",
    "                \"+1:token.isupper()\": None,\n",
    "                \"+1:postag\": None,\n",
    "            }\n",
    "        )\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    else:\n",
    "        features[\"EOS\"] = True\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [token2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for _, _, label in sent]\n",
    "\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, _, _ in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa25a9d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae60f5765168b4432b3a0e8fe1b58eee",
     "grade": true,
     "grade_id": "cell-ce2404350ff8e421",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ex3_b1 = [\n",
    "    (\"Thousands\", \"NNS\", \"B-CARDINAL\"),\n",
    "    (\"of\", \"IN\", \"O\"),\n",
    "    (\"demonstrators\", \"NNS\", \"O\"),\n",
    "    (\"have\", \"VBP\", \"O\"),\n",
    "    (\"marched\", \"VBN\", \"O\"),\n",
    "    (\"through\", \"IN\", \"O\"),\n",
    "    (\"London\", \"NNP\", \"B-GPE\"),\n",
    "    (\"to\", \"TO\", \"O\"),\n",
    "    (\"protest\", \"VB\", \"O\"),\n",
    "    (\"the\", \"DT\", \"O\"),\n",
    "    (\"war\", \"NN\", \"O\"),\n",
    "    (\"in\", \"IN\", \"O\"),\n",
    "    (\"Iraq\", \"NNP\", \"B-GPE\"),\n",
    "    (\"and\", \"CC\", \"O\"),\n",
    "    (\"demand\", \"VB\", \"O\"),\n",
    "    (\"the\", \"DT\", \"O\"),\n",
    "    (\"withdrawal\", \"NN\", \"O\"),\n",
    "    (\"of\", \"IN\", \"O\"),\n",
    "    (\"British\", \"JJ\", \"B-NORP\"),\n",
    "    (\"troops\", \"NNS\", \"O\"),\n",
    "    (\"from\", \"IN\", \"O\"),\n",
    "    (\"that\", \"DT\", \"O\"),\n",
    "    (\"country\", \"NN\", \"O\"),\n",
    "    (\".\", \".\", \"O\"),\n",
    "]\n",
    "\n",
    "sol3_b1 = {\n",
    "    \"bias\": 1.0,\n",
    "    \"token.lower()\": \"through\",\n",
    "    \"token[-3:]\": \"ugh\",\n",
    "    \"token[-2:]\": \"gh\",\n",
    "    \"token.isupper()\": False,\n",
    "    \"token.istitle()\": False,\n",
    "    \"token.isdigit()\": False,\n",
    "    \"postag\": \"IN\",\n",
    "    \"postag[:2]\": \"IN\",\n",
    "    \"-1:token.lower()\": \"marched\",\n",
    "    \"-1:token.istitle()\": False,\n",
    "    \"-1:token.isupper()\": False,\n",
    "    \"-1:postag\": \"VBN\",\n",
    "    \"+1:token.lower()\": \"london\",\n",
    "    \"+1:token.istitle()\": True,\n",
    "    \"+1:token.isupper()\": False,\n",
    "    \"+1:postag\": \"NNP\",\n",
    "}\n",
    "\n",
    "assert sent2features(ex3_b1)[5] == sol3_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3e886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in processed]\n",
    "y = [sent2labels(s) for s in processed]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077d0682",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c876edf1ff1c884b68896d397696429a",
     "grade": false,
     "grade_id": "cell-6f8321146de778a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If the training lasts longer than ~10 minutes, you can reduce `max_iterations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddbc09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm=\"lbfgs\", c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6075ca4c",
   "metadata": {},
   "source": [
    "CRF should heavily outperform our previous attempt with the classifier. Check the performance without the `O` tag. If you wish, you can see how $F_1$ changes if you include the `O` tag, simply by setting `labels=classes` in `flat_classification_report`. The benefits of solving NER as a sequence labeling task should be obvious after you inspect the margin of improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a074f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49baecdf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28e4d706e8b2e88cc70ad6eb97ed47cb",
     "grade": false,
     "grade_id": "cell-101a4c137df7738a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's explore the top (un)likely transitions. Can you spot any expected patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc924d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_trans = 20\n",
    "\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-14s -> %-14s: %0.5f\" % (label_from, label_to, weight))\n",
    "\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(top_n_trans))\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-top_n_trans:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362aae9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "678006c1883cea5032550f0a4f5b2c26",
     "grade": false,
     "grade_id": "cell-fd1243cfc20e9ac9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Additionally, let's take a look at the most important features for specific tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce0edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_feat = 30\n",
    "\n",
    "\n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.5f %-14s %s\" % (weight, label, attr))\n",
    "\n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(top_n_feat))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Top negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-top_n_feat:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee17db",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e42321e71f2eafb801fc75c13a868d37",
     "grade": false,
     "grade_id": "cell-339eac0c87542c35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's conclude this assignment with an overview of CRF feature importance using the `eli5` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d1df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "\n",
    "eli5.show_weights(crf, top=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
