{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77230ee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed8a00df369ce38f9743ed412973d72b",
     "grade": false,
     "grade_id": "cell-cbdf7d65ea58446b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "University of Zagreb\\\n",
    "Faculty of Electrical Engineering and Computing\n",
    "\n",
    "## Text Analysis and Retrieval 2021/2022\n",
    "https://www.fer.unizg.hr/predmet/apt/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee22e58",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9b48444c442d59c241b49ba429238dd",
     "grade": false,
     "grade_id": "cell-5e9c1e104dec0dd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "------------------------------\n",
    "\n",
    "### Semantics\n",
    "### LAB 2\n",
    "\n",
    "\n",
    "*Version: 1.0*\n",
    "\n",
    "(c) 2022 Josip Jukić, Jan Šnajder\n",
    "\n",
    "Submission deadline: **May 4, 2022, 23:59 CET** \n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6333437b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6233aca5abb9b3f8b6a7a6080fb096fb",
     "grade": false,
     "grade_id": "cell-b25d76fa7c847af2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "Hello visitor, this lab assignment consists of three parts. Your task boils down to filling out the missing parts of code and evaluating the cells. These parts are indicated by the \"YOUR CODE HERE\" template.\n",
    "\n",
    "Each subtask is supplemented by several tests that you can run. Apart from that, there are additional test that will be executed after submition. If your solution is valid and it passes all of the visible tests, there shouldn't be any problems with the additional tests.\n",
    "\n",
    "**IMPORTANT: Don't change the names of the predefined methods or random seeds**, because the tests won't execute properly.\n",
    "\n",
    "You're required to do this assignment **on your own**.\n",
    "\n",
    "If you stumble upon problems, please refer to josip.jukic@fer.hr for office hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336f31b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd1654b2c7c8de8e1d1cfaeeee261ec2",
     "grade": false,
     "grade_id": "cell-150c23ae802b9522",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52503faa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d5b35025abd60b2ec4d24bb43494673",
     "grade": false,
     "grade_id": "cell-95afad8333fec3bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1. Paraphrase identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e247b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8003466213056de71915ec4c716b5f6d",
     "grade": false,
     "grade_id": "cell-7caecd650447b599",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The goal of paraphrase identification is to determine whether a pair of sentences have the same meaning. In this assignment, we will use the [MRPC](https://paperswithcode.com/dataset/mrpc) dataset, a part of the [GLUE benchmark](https://gluebenchmark.com/).\n",
    "\n",
    "Load the data frames (train & test) and explore their structure. The column `label` indicates whether a given pair of sentences is semantically equivalent (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85def3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load CSV files.\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedb727d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "222ebb1c9eb1e6f50e52bad8b4e68a83",
     "grade": false,
     "grade_id": "cell-05a53297f6695a37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The library that will do the heavy lifting for this task is [Podium](https://takelab.fer.hr/podium/), TakeLab's data loading and preprocessing tool for NLP. We advise you to take a look at the official documenation as well as the [walkthrough](https://takelab.fer.hr/podium/walkthrough.html) examples. Additionally, go through the main primitives: [Vocab](https://takelab.fer.hr/podium/package_reference/vocab_and_fields.html#vocab), [Field](https://takelab.fer.hr/podium/package_reference/vocab_and_fields.html#field), and [Dataset](https://takelab.fer.hr/podium/package_reference/datasets.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bfcbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from podium import Vocab, Field, LabelField\n",
    "from podium.datasets import TabularDataset\n",
    "from podium.vectorizers import GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e673b2d3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fc507e3ad32586f15570905da09ec88",
     "grade": false,
     "grade_id": "cell-9c4e4d599e282ec6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (a)\n",
    "\n",
    "Construct three fields: `sentence1` (Field), `sentence2` (Field), and `label` (LabelField). Transform the sentences to lower case using the attribute `pretokenize_hooks`. Refer to the [documentation](https://takelab.fer.hr/podium/preprocessing.html#hooks) to see how this can be achieved.\n",
    "\n",
    "In order to model semantics, we will utilize [GloVe](https://nlp.stanford.edu/projects/glove/) distributional word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31db5d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4b67c7d503b99e70e3ea563ed12c399",
     "grade": false,
     "grade_id": "cell-dff7bf4dffadbf13",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_vocab_size = 10_000\n",
    "vocab = Vocab(max_size=max_vocab_size, min_freq=2)\n",
    "\n",
    "S1 = None # Sentence1 field\n",
    "S2 = None # Sentence2 field\n",
    "LABEL = None # Label field\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "fields = [\n",
    "    S1,\n",
    "    S2,\n",
    "    LABEL,\n",
    "]\n",
    "\n",
    "train = TabularDataset.from_pandas(df_train, fields)\n",
    "test = TabularDataset.from_pandas(df_test, fields)\n",
    "train.finalize_fields()\n",
    "\n",
    "glove = GloVe()\n",
    "# Load only the vectors of vocab words.\n",
    "embeddings = glove.load_vocab(vocab)\n",
    "\n",
    "# Generate padded batch.\n",
    "train_batch = train.batch(add_padding=True)\n",
    "test_batch = test.batch(add_padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d202fbfc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23dbb38bd32d5dcac039e1affb20c4e3",
     "grade": true,
     "grade_id": "cell-d078098275346006",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert \"washington\" in vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7d133",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "498106dc5b2f653a5e0a2d8f1cebe010",
     "grade": false,
     "grade_id": "cell-6f84a2e14ea825e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Generated batch stores values for the corresponding fields, which can be accessed with the dot notation. See the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88ca1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch.sentence1, train_batch.sentence2, train_batch.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82a9ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "caf466ce0fd3fdf4cda671794ee40d56",
     "grade": false,
     "grade_id": "cell-29c126a7fde72a9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (b)\n",
    "\n",
    "Implement `cosine_similarity`, which computes cosine similarities of two 2D arrays across their second axis (index = 1). Refer to the tests below to see a concrete example. [np.einsum](https://numpy.org/doc/stable/reference/generated/numpy.einsum.html) and [np.linalg.norm](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html) may be useful for this task. However, you are not obliged to use those methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc501e6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89b665abb2ca111c1c5cb0125d3f81df",
     "grade": false,
     "grade_id": "cell-f0747bf03a37381a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    \"\"\"\n",
    "    Receives two 2D numpy arrays and calculates cosine similarity across the second axis.\n",
    "    For examples, if `a` and `b` have shape (32, 10), the resulting array should have shape (32,).\n",
    "    \n",
    "    Returns:\n",
    "        1D numpy array with cosine similarities\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7a058",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb7c554cbdc752cb7f9ea79f065403d5",
     "grade": true,
     "grade_id": "cell-6710738e2774f997",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "a = np.array(\n",
    "    [\n",
    "        [0.79674043, -0.21774995, 0.24626283, -1.92507862, -0.44471655],\n",
    "        [-0.83365243, -1.05258529, -0.69114343, 1.94794818, 0.81859483],\n",
    "        [-1.1742791, 0.39978046, -1.14265924, 1.50492221, 0.99339915],\n",
    "        [0.58896543, 0.8214453, -0.27131406, 0.45817815, -0.21055904],\n",
    "    ]\n",
    ")\n",
    "\n",
    "b = np.array(\n",
    "    [\n",
    "        [0.20286607, 0.34114231, -1.14127489, 0.11783557, -0.43729267],\n",
    "        [0.34177672, -1.66142734, 1.13159559, 0.07148497, 0.24896589],\n",
    "        [-0.10376178, 0.30639966, 0.54675361, -0.04626362, 0.1408809],\n",
    "        [-0.6056932, -1.24619744, -0.2720515, 1.26427211, 1.47021337],\n",
    "    ]\n",
    ")\n",
    "\n",
    "sol = np.array([-0.08127636, 0.1919786, -0.19251815, -0.37211115])\n",
    "\n",
    "assert np.isclose(cosine_similarity(a, b), sol).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48c7a90",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed4c8c70dac9cff2987b9d00a3696cb9",
     "grade": false,
     "grade_id": "cell-59a7a22cb3eb23fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (c)\n",
    "Implement `top_n`, which retrieves the sorted indices of top `n` values in a numpy array. Refer to the test below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b0a6c3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98ec8f9312ee6d068f6a60f461a3e8c7",
     "grade": false,
     "grade_id": "cell-aa7506bc0511eecf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def top_n(sims, n=10):\n",
    "    \"\"\"\n",
    "    Receives a numpy array `sims` and finds the indices of the top `n` highest similarities.\n",
    "    The indices are returned in the ascending order (from lowest to highest index).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614bec35",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45131a63bcff88d79a43b1b0f136bf31",
     "grade": true,
     "grade_id": "cell-061d712459e09a1a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (top_n(np.array([0.1, 0.5, 0.2, 0.3, 0.9]), 2) == np.array([1, 4])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e3234",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3725ea1f2ee3d640d78a5281d72f8d0",
     "grade": false,
     "grade_id": "cell-f0bd1b3236a4dab6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (d)\n",
    "We need to somehow transform the sequences to fixed-size vectors. We will explore several simple approaches.\n",
    "\n",
    "Extract word embeddings for sentence1 and sentence2 (both for train and test), using `train_batch`, `test_batch`, and `embeddings`. Additionally, compute the mean embedding for both fields and both sets. Store them to `sentence1_train_mean`, `sentence2_train_mean`, `sentence1_test_mean`, and `sentence2_test_mean`.\n",
    "\n",
    "Once you compute the means, retrieve and print out the top 10 most similar sentence pairs from the train set using the previously implemented methods `cosine_similarity` and `top_n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04849468",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e45f81166fe57966be7ee6ee95366805",
     "grade": false,
     "grade_id": "cell-63d484fa72557c59",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sentence1_train, sentence2_train = None, None\n",
    "sentence1_test, sentence2_test = None, None\n",
    "sentence1_train_mean, sentence2_train_mean = None, None\n",
    "sentence1_test_mean, sentence2_test_mean = None, None\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121510d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "394d265fbf16672028e669a8b635107e",
     "grade": true,
     "grade_id": "cell-c1f16db9cca4da7a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sentence1_train_mean.shape == (len(train), 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3125fd5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7c8809f920b20c128e5ad963ff35efa",
     "grade": false,
     "grade_id": "cell-05e631d6a5c424a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (e)\n",
    "Now use the computed means to create representations. You should make two variants: `*_mul`**multiplies the values element-wise** and `*_cat` simply **concatenates** the means from sentence1 and sentence2.\n",
    "Load the train and test labels from their corresponding batches. Make sure that the label array is 1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b61c345",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10b5d34acf8980c01e4f36b53e344be7",
     "grade": false,
     "grade_id": "cell-818c0bfd3a022b26",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_mul, X_test_mul = None, None\n",
    "X_train_cat, X_test_cat = None, None\n",
    "y_train, y_test = None, None\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b3dc0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a0713d978a5ee0f9ebe0a59e9c13304",
     "grade": true,
     "grade_id": "cell-bb7c231933127781",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert X_train_mul.shape == (len(train), 300)\n",
    "assert X_train_cat.shape == (len(train), 600)\n",
    "assert y_train.shape == (len(train),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b70b551",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8fd42a773e54c9ab72a528fe134fc068",
     "grade": false,
     "grade_id": "cell-68f0b46758a9f780",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### (f)\n",
    "Finally, let's exploit the fruits of our labor by building a classifier that will identify paraphrases. Implement `train_model` that trains an [`sklearn`](https://scikit-learn.org/stable/) model and returns the fitted model. You may use any `sklearn` model, but you need to achieve **binary $F_1$ generalization score higher than 0.4** for both represenations (multiplied and concatenated) to pass the tests. To calculate $F_1$ with `sklearn.metrics.f1_score`, set `average=\"binary\"`. See the example bellow. For additional information, we advise you to use `classification_report`. Remember that the MRPC dataset is quite challenging and we're using a simple approach, so don't be surprised with low binary $F_1$ scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd8d1d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6d61f9adc576122b1252072b5889e9d",
     "grade": false,
     "grade_id": "cell-1a247f119b6b096f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Fit and return the fitted sklearn model.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b66c94d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb0739006c3e674b79c4928d8b0a8817",
     "grade": true,
     "grade_id": "cell-adfee54218548429",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec8390e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c8bc51dd6134adb177418358da87694",
     "grade": true,
     "grade_id": "cell-440e012cfbed3809",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
